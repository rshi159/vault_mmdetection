{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCMycQ_2U8SA"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://github.com/open-mmlab/mmdetection/raw/3.x/resources/mmdet-logo.png\" width=\"600\"/>\n",
        "  <div>&nbsp;</div>\n",
        "  <div align=\"center\">\n",
        "    <b><font size=\"5\">OpenMMLab website</font></b>\n",
        "    <sup>\n",
        "      <a href=\"https://openmmlab.com\">\n",
        "        <i><font size=\"4\">HOT</font></i>\n",
        "      </a>\n",
        "    </sup>\n",
        "    &nbsp;&nbsp;&nbsp;&nbsp;\n",
        "    <b><font size=\"5\">OpenMMLab platform</font></b>\n",
        "    <sup>\n",
        "      <a href=\"https://platform.openmmlab.com\">\n",
        "        <i><font size=\"4\">TRY IT OUT</font></i>\n",
        "      </a>\n",
        "    </sup>\n",
        "  </div>\n",
        "  <div>&nbsp;</div>\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/open-mmlab/mmdetection/blob/dev-3.x/demo/inference_demo.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "[![PyPI](https://img.shields.io/pypi/v/mmdet)](https://pypi.org/project/mmdet)\n",
        "[![docs](https://img.shields.io/badge/docs-latest-blue)](https://mmdetection.readthedocs.io/en/latest/)\n",
        "[![badge](https://github.com/open-mmlab/mmdetection/workflows/build/badge.svg)](https://github.com/open-mmlab/mmdetection/actions)\n",
        "[![codecov](https://codecov.io/gh/open-mmlab/mmdetection/branch/master/graph/badge.svg)](https://codecov.io/gh/open-mmlab/mmdetection)\n",
        "[![license](https://img.shields.io/github/license/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/blob/master/LICENSE)\n",
        "[![open issues](https://isitmaintained.com/badge/open/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/issues)\n",
        "[![issue resolution](https://isitmaintained.com/badge/resolution/open-mmlab/mmdetection.svg)](https://github.com/open-mmlab/mmdetection/issues)\n",
        "\n",
        "[üìòDocumentation](https://mmdetection.readthedocs.io/en/3.x/) |\n",
        "[üõ†Ô∏èInstallation](https://mmdetection.readthedocs.io/en/3.x/get_started.html) |\n",
        "[üëÄModel Zoo](https://mmdetection.readthedocs.io/en/3.x/model_zoo.html) |\n",
        "[üÜïUpdate News](https://mmdetection.readthedocs.io/en/3.x/notes/changelog.html) |\n",
        "[üöÄOngoing Projects](https://github.com/open-mmlab/mmdetection/projects) |\n",
        "[ü§îReporting Issues](https://github.com/open-mmlab/mmdetection/issues/new/choose)\n",
        "\n",
        "</div>\n",
        "\n",
        "<div align=\"center\">\n",
        "  <a href=\"https://openmmlab.medium.com/\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/219255827-67c1a27f-f8c5-46a9-811d-5e57448c61d1.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://discord.com/channels/1037617289144569886/1046608014234370059\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/218347213-c080267f-cbb6-443e-8532-8e1ed9a58ea9.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://twitter.com/OpenMMLab\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/218346637-d30c8a0f-3eba-4699-8131-512fb06d46db.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://www.youtube.com/openmmlab\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/218346691-ceb2116a-465a-40af-8424-9f30d2348ca9.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://space.bilibili.com/1293512903\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/219026751-d7d14cce-a7c9-4e82-9942-8375fca65b99.png\" width=\"3%\" alt=\"\" /></a>\n",
        "  <img src=\"https://user-images.githubusercontent.com/25839884/218346358-56cc8e2f-a2b8-487f-9088-32480cceabcf.png\" width=\"3%\" alt=\"\" />\n",
        "  <a href=\"https://www.zhihu.com/people/openmmlab\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://user-images.githubusercontent.com/25839884/219026120-ba71e48b-6e94-4bd4-b4e9-b7d175b5e362.png\" width=\"3%\" alt=\"\" /></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGYwt_UjIrqp"
      },
      "source": [
        "# Inferencer\n",
        "\n",
        "In this tutorial, you will learn how to perform inference with a MMDetection `DetInferencer`.\n",
        "\n",
        "Let's start!\n",
        "\n",
        "```{note}\n",
        "The commands in this tutorial are mainly for Colab.\n",
        "You can click the button above, `Open in Colab`, to run this notebook in Colab.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJxJHruNLb7Y"
      },
      "source": [
        "## Install MMDetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi4LPmsR66sy",
        "outputId": "0077a9a3-0183-4002-fe7a-2a12f020cf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Tue_Oct_29_23:50:19_PDT_2024\n",
            "Cuda compilation tools, release 12.6, V12.6.85\n",
            "Build cuda_12.6.r12.6/compiler.35059454_0\n",
            "gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0\n",
            "Copyright (C) 2023 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
            "    await result\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipykernel_580804/3970891079.py\", line 6, in <module>\n",
            "    import sys, torch, numpy as np\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python: /home/robun2/.venvs/mmdet311/bin/python\n",
            "torch: 2.1.2+cu121 cuda: 12.1 avail: True\n",
            "numpy: 2.2.6\n",
            "mmcv: 2.2.0 roi_align: True\n",
            "mmengine: 0.10.7\n",
            "mmdet: 3.3.0\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version\n",
        "\n",
        "import sys, torch, numpy as np\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import mmcv\n",
        "import mmcv.ops as ops\n",
        "import mmengine\n",
        "import mmdet\n",
        "\n",
        "print(\"python:\", sys.executable)\n",
        "print(\"torch:\", torch.__version__, \"cuda:\", torch.version.cuda, \"avail:\", torch.cuda.is_available())\n",
        "print(\"numpy:\", np.__version__)\n",
        "print(\"mmcv:\", mmcv.__version__, \"roi_align:\", hasattr(ops, \"roi_align\"))\n",
        "print(\"mmengine:\", mmengine.__version__)\n",
        "print(\"mmdet:\", mmdet.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkGnB9WyHSXB",
        "outputId": "5945fe0b-13a5-4f1b-dff9-8beb1df67ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openmim in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (0.3.9)\n",
            "Requirement already satisfied: Click in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (8.2.1)\n",
            "Requirement already satisfied: colorama in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (0.4.6)\n",
            "Requirement already satisfied: model-index in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (0.0.10)\n",
            "Requirement already satisfied: pandas in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (2.3.1)\n",
            "Requirement already satisfied: pip>=19.3 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (25.2)\n",
            "Requirement already satisfied: requests in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (2.28.2)\n",
            "Requirement already satisfied: rich in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (13.4.2)\n",
            "Requirement already satisfied: tabulate in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from model-index->openmim) (6.0.2)\n",
            "Requirement already satisfied: markdown in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from model-index->openmim) (3.8.2)\n",
            "Requirement already satisfied: ordered-set in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from model-index->openmim) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from opendatalab->openmim) (3.23.0)\n",
            "Requirement already satisfied: tqdm in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from opendatalab->openmim) (4.65.2)\n",
            "Requirement already satisfied: openxlab in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from opendatalab->openmim) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from requests->openmim) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from requests->openmim) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from requests->openmim) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from requests->openmim) (2025.8.3)\n",
            "Requirement already satisfied: filelock~=3.14.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openxlab->opendatalab->openmim) (3.14.0)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openxlab->opendatalab->openmim) (2.17.0)\n",
            "Requirement already satisfied: packaging~=24.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openxlab->opendatalab->openmim) (24.2)\n",
            "Requirement already satisfied: pytz~=2023.3 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openxlab->opendatalab->openmim) (2023.4)\n",
            "Requirement already satisfied: setuptools~=60.2.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from openxlab->opendatalab->openmim) (60.2.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.0)\n",
            "Requirement already satisfied: six in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from rich->openmim) (2.19.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (45.0.6)\n",
            "Requirement already satisfied: cffi>=1.14 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from cffi>=1.14->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from pandas->openmim) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from pandas->openmim) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from pandas->openmim) (2025.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/home/robun2/.venvs/mmdet311/bin/mim\", line 7, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 1442, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 1363, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 1830, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 1226, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 794, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mim/commands/install.py\", line 72, in cli\n",
            "    exit_code = install(list(args), index_url=index_url, is_yes=is_yes)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mim/commands/install.py\", line 128, in install\n",
            "    install_args += ['-f', get_mmcv_full_find_link(mmcv_base_url)]\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mim/commands/install.py\", line 165, in get_mmcv_full_find_link\n",
            "    torch_v, cuda_v = get_torch_cuda_version()\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mim/utils/utils.py\", line 338, in get_torch_cuda_version\n",
            "    import torch\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/index.html\n",
            "Requirement already satisfied: mmengine>=0.7.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (0.10.7)\n",
            "Requirement already satisfied: addict in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.7.0) (2.4.0)\n",
            "Requirement already satisfied: matplotlib in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.7.0) (3.10.5)\n",
            "Requirement already satisfied: numpy in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.7.0) (2.2.6)\n",
            "Requirement already satisfied: pyyaml in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.7.0) (6.0.2)\n",
            "Requirement already satisfied: rich in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.7.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.7.0) (3.1.0)\n",
            "Requirement already satisfied: yapf in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.7.0) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.7.0) (4.12.0.88)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.7.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.7.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.7.0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.7.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.7.0) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.7.0) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.7.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.7.0) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.7.0) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from rich->mmengine>=0.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from rich->mmengine>=0.7.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.7.0) (0.1.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from yapf->mmengine>=0.7.0) (4.3.8)\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/home/robun2/.venvs/mmdet311/bin/mim\", line 7, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 1442, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 1363, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 1830, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 1226, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/click/core.py\", line 794, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mim/commands/install.py\", line 72, in cli\n",
            "    exit_code = install(list(args), index_url=index_url, is_yes=is_yes)\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mim/commands/install.py\", line 128, in install\n",
            "    install_args += ['-f', get_mmcv_full_find_link(mmcv_base_url)]\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mim/commands/install.py\", line 165, in get_mmcv_full_find_link\n",
            "    torch_v, cuda_v = get_torch_cuda_version()\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mim/utils/utils.py\", line 338, in get_torch_cuda_version\n",
            "    import torch\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/index.html\n",
            "Collecting mmcv>=2.0.0rc4\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/mmcv-2.2.0-cp311-cp311-manylinux1_x86_64.whl (94.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.1/94.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmcv>=2.0.0rc4) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmcv>=2.0.0rc4) (0.10.7)\n",
            "Requirement already satisfied: numpy in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmcv>=2.0.0rc4) (2.2.6)\n",
            "Requirement already satisfied: packaging in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmcv>=2.0.0rc4) (24.2)\n",
            "Requirement already satisfied: Pillow in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmcv>=2.0.0rc4) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmcv>=2.0.0rc4) (6.0.2)\n",
            "Requirement already satisfied: yapf in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmcv>=2.0.0rc4) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmcv>=2.0.0rc4) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.10.5)\n",
            "Requirement already satisfied: rich in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc4) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc4) (0.1.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from yapf->mmcv>=2.0.0rc4) (4.3.8)\n",
            "Installing collected packages: mmcv\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mmdet 3.3.0 requires mmcv<2.2.0,>=2.0.0rc4; extra == \"mim\", but you have mmcv 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mmcv-2.2.0\n",
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 38023, done.\u001b[K\n",
            "remote: Total 38023 (delta 0), reused 0 (delta 0), pack-reused 38023 (from 1)\u001b[K\n",
            "Receiving objects: 100% (38023/38023), 63.27 MiB | 14.29 MiB/s, done.\n",
            "Resolving deltas: 100% (26208/26208), done.\n",
            "/home/robun2/Documents/vault_conveyor_tracking/vault_mmdetection/demo/mmdetection\n",
            "Obtaining file:///home/robun2/Documents/vault_conveyor_tracking/vault_mmdetection/demo/mmdetection\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmdet==3.3.0) (3.10.5)\n",
            "Requirement already satisfied: numpy in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmdet==3.3.0) (2.2.6)\n",
            "Requirement already satisfied: pycocotools in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmdet==3.3.0) (2.0.10)\n",
            "Requirement already satisfied: scipy in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmdet==3.3.0) (1.16.1)\n",
            "Requirement already satisfied: shapely in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmdet==3.3.0) (2.1.1)\n",
            "Requirement already satisfied: six in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmdet==3.3.0) (1.17.0)\n",
            "Requirement already satisfied: terminaltables in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmdet==3.3.0) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from mmdet==3.3.0) (4.65.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmdet==3.3.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmdet==3.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmdet==3.3.0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmdet==3.3.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmdet==3.3.0) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmdet==3.3.0) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmdet==3.3.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/robun2/.venvs/mmdet311/lib/python3.11/site-packages (from matplotlib->mmdet==3.3.0) (2.9.0.post0)\n",
            "Installing collected packages: mmdet\n",
            "\u001b[33m  DEPRECATION: Legacy editable install of mmdet==3.3.0 from file:///home/robun2/Documents/vault_conveyor_tracking/vault_mmdetection/demo/mmdetection (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-3.3.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# # install dependencies\n",
        "# %pip install -U openmim\n",
        "# !mim install \"mmengine>=0.7.0\"\n",
        "# !mim install \"mmcv>=2.0.0rc4\"\n",
        "\n",
        "# # Install mmdetection\n",
        "# !rm -rf mmdetection\n",
        "# !git clone https://github.com/open-mmlab/mmdetection.git -b dev-3.x\n",
        "# %cd mmdetection\n",
        "\n",
        "# %pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YeUiqAoCaoV",
        "outputId": "06e4c803-ac46-49e6-b8fa-1a85c23fa482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sys.platform: linux\n",
            "Python: 3.11.13 (main, Jun  4 2025, 08:57:30) [GCC 13.3.0]\n",
            "CUDA available: True\n",
            "MUSA available: False\n",
            "numpy_random_seed: 2147483648\n",
            "GPU 0: NVIDIA GeForce RTX 4090\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 12.6, V12.6.85\n",
            "GCC: x86_64-linux-gnu-gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0\n",
            "PyTorch: 2.1.2+cu121\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX512\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "TorchVision: 0.16.2+cu121\n",
            "OpenCV: 4.12.0\n",
            "MMEngine: 0.10.7\n",
            "MMDetection: 3.3.0+cfd5d3a\n"
          ]
        }
      ],
      "source": [
        "from mmengine.utils import get_git_hash\n",
        "from mmengine.utils.dl_utils import collect_env as collect_base_env\n",
        "\n",
        "import mmdet\n",
        "\n",
        "\n",
        "def collect_env():\n",
        "    \"\"\"Collect the information of the running environments.\"\"\"\n",
        "    env_info = collect_base_env()\n",
        "    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n",
        "    return env_info\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for name, val in collect_env().items():\n",
        "        print(f'{name}: {val}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLgFRMtP91ue"
      },
      "source": [
        "## `DetInferencer`\n",
        "\n",
        "### Basic Usage\n",
        "\n",
        "We use the high-level API `DetInferencer` implemented in the MMDetection. This API is created to ease the inference process. The details of the codes can be found [here](https://github.com/open-mmlab/mmdetection/blob/dev-3.x/mmdet/apis/det_inferencer.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6fa2cda48fda43f9bf53a0f533392eba",
            "0226fedc26044ab2abdccc4fcbe226f8"
          ]
        },
        "id": "WJHpC402p2w9",
        "outputId": "c2326326-d198-4fce-ec0e-a9cc2e35ba09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_tiny_8xb32-300e_coco/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
            "\n",
            "08/10 15:24:50 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
              "Jupyter support\n",
              "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
              "</pre>\n"
            ],
            "text/plain": [
              "/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for \n",
              "Jupyter support\n",
              "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/robun2/.venvs/mmdet311/lib/python3.11/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
            "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m inferencer = DetInferencer(\u001b[33m'\u001b[39m\u001b[33mrtmdet_tiny_8xb32-300e_coco\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43minferencer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdemo.jpg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m..\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vault_conveyor_tracking/vault_mmdetection/demo/mmdetection/mmdet/apis/det_inferencer.py:401\u001b[39m, in \u001b[36mDetInferencer.__call__\u001b[39m\u001b[34m(self, inputs, batch_size, return_vis, show, wait_time, no_save_vis, draw_pred, pred_score_thr, return_datasamples, print_result, no_save_pred, out_dir, texts, stuff_texts, custom_entities, tokens_positive, **kwargs)\u001b[39m\n\u001b[32m    397\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m.preprocess(\n\u001b[32m    398\u001b[39m     ori_inputs, batch_size=batch_size, **preprocess_kwargs)\n\u001b[32m    400\u001b[39m results_dict = {\u001b[33m'\u001b[39m\u001b[33mpredictions\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mvisualization\u001b[39m\u001b[33m'\u001b[39m: []}\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mori_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mInference\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisualization\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mori_imgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg_out_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvisualize_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/mmdet311/lib/python3.11/site-packages/rich/progress.py:168\u001b[39m, in \u001b[36mtrack\u001b[39m\u001b[34m(sequence, description, total, auto_refresh, console, transient, get_time, refresh_per_second, style, complete_style, finished_style, pulse_style, update_period, disable, show_speed)\u001b[39m\n\u001b[32m    157\u001b[39m progress = Progress(\n\u001b[32m    158\u001b[39m     *columns,\n\u001b[32m    159\u001b[39m     auto_refresh=auto_refresh,\n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m     disable=disable,\n\u001b[32m    165\u001b[39m )\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m progress:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m progress.track(\n\u001b[32m    169\u001b[39m         sequence, total=total, description=description, update_period=update_period\n\u001b[32m    170\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/mmdet311/lib/python3.11/site-packages/rich/progress.py:1210\u001b[39m, in \u001b[36mProgress.track\u001b[39m\u001b[34m(self, sequence, total, task_id, description, update_period)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.live.auto_refresh:\n\u001b[32m   1209\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _TrackThread(\u001b[38;5;28mself\u001b[39m, task_id, update_period) \u001b[38;5;28;01mas\u001b[39;00m track_thread:\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrack_thread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompleted\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vault_conveyor_tracking/vault_mmdetection/demo/mmdetection/mmdet/apis/det_inferencer.py:261\u001b[39m, in \u001b[36mDetInferencer.preprocess\u001b[39m\u001b[34m(self, inputs, batch_size, **kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Process the inputs into a model-feedable format.\u001b[39;00m\n\u001b[32m    238\u001b[39m \n\u001b[32m    239\u001b[39m \u001b[33;03mCustomize your preprocess by overriding this method. Preprocess should\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \u001b[33;03m    Any: Data processed by the ``pipeline`` and ``collate_fn``.\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m chunked_data = \u001b[38;5;28mself\u001b[39m._get_chunk_data(inputs, batch_size)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m.collate_fn, chunked_data)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vault_conveyor_tracking/vault_mmdetection/demo/mmdetection/mmdet/apis/det_inferencer.py:288\u001b[39m, in \u001b[36mDetInferencer._get_chunk_data\u001b[39m\u001b[34m(self, inputs, chunk_size)\u001b[39m\n\u001b[32m    284\u001b[39m             chunk_data.append(\n\u001b[32m    285\u001b[39m                 (ori_inputs_,\n\u001b[32m    286\u001b[39m                  \u001b[38;5;28mself\u001b[39m.pipeline(copy.deepcopy(inputs_))))\n\u001b[32m    287\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m             chunk_data.append((inputs_, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m chunk_data\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/mmdet311/lib/python3.11/site-packages/mmengine/dataset/base_dataset.py:60\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call function to apply transforms sequentially.\u001b[39;00m\n\u001b[32m     52\u001b[39m \n\u001b[32m     53\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33;03m   dict: Transformed data.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     data = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# The transform will return None when it failed to load images or\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# cannot find suitable augmentation parameters to augment the data.\u001b[39;00m\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# Here we simply return None if the transform returns None and the\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# dataset will handle it by randomly selecting another data sample.\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/mmdet311/lib/python3.11/site-packages/mmcv/transforms/base.py:12\u001b[39m, in \u001b[36mBaseTransform.__call__\u001b[39m\u001b[34m(self, results)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m     10\u001b[39m              results: Dict) -> Optional[Union[Dict, Tuple[List, List]]]:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vault_conveyor_tracking/vault_mmdetection/demo/mmdetection/mmdet/datasets/transforms/formatting.py:84\u001b[39m, in \u001b[36mPackDetInputs.transform\u001b[39m\u001b[34m(self, results)\u001b[39m\n\u001b[32m     82\u001b[39m         img = to_tensor(img)\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m         img = \u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m).contiguous()\n\u001b[32m     86\u001b[39m     packed_results[\u001b[33m'\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m'\u001b[39m] = img\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mgt_ignore_flags\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m results:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/mmdet311/lib/python3.11/site-packages/mmcv/transforms/formatting.py:31\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np.ndarray):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mmengine.is_str(data):\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor(data)\n",
            "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
          ]
        }
      ],
      "source": [
        "from mmdet.apis import DetInferencer\n",
        "\n",
        "# Initialize the DetInferencer\n",
        "inferencer = DetInferencer('rtmdet_tiny_8xb32-300e_coco')\n",
        "\n",
        "# Perform inference\n",
        "inferencer('demo.jpg', out_dir='..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "34JfPWRRSlNh",
        "outputId": "8eec8bc4-4824-47ac-b10f-41538422fb28"
      },
      "outputs": [],
      "source": [
        "# Show the output image\n",
        "from PIL import Image\n",
        "Image.open('./output/vis/demo.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-53WPeyBqRHe"
      },
      "source": [
        "### Initialization\n",
        "\n",
        "Each Inferencer must be initialized with a model. You can also choose the inference device during initialization.\n",
        "\n",
        "#### Model Initialization\n",
        "\n",
        "- To infer with MMDetection's pre-trained model, passing its name to the argument `model` can work. The weights will be automatically downloaded and loaded from OpenMMLab's model zoo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbMu3IPtv-cX",
        "outputId": "2bceb594-06c8-4c18-e8c6-b1816b0acb23"
      },
      "outputs": [],
      "source": [
        "inferencer = DetInferencer(model='rtmdet_tiny_8xb32-300e_coco')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwKtnol3TQlM"
      },
      "source": [
        "There is a very easy to list all model names in MMDetection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kYfK3ssTIQE",
        "outputId": "88c4fbb9-bb92-42af-baaa-14cee5b5bdc1"
      },
      "outputs": [],
      "source": [
        "# models is a list of model names, and them will print automatically\n",
        "models = DetInferencer.list_models('mmdet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-25HR9HTZvr"
      },
      "source": [
        "You can load another weight by passing its path/url to `weights`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4doHX4exvS1",
        "outputId": "54ac0be2-835f-4390-aa0e-3be5236d8cc9"
      },
      "outputs": [],
      "source": [
        "!mkdir ./checkpoints\n",
        "!mim download mmdet --config rtmdet_tiny_8xb32-300e_coco --dest ./checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LQB4EC-Tako",
        "outputId": "2cc0960e-d5b5-4c3a-8a0c-cec23989f6a0"
      },
      "outputs": [],
      "source": [
        "# Setup a checkpoint file to load\n",
        "checkpoint = './checkpoints/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n",
        "\n",
        "# Initialize the DetInferencer\n",
        "inferencer = DetInferencer(model='rtmdet_tiny_8xb32-300e_coco', weights=checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atft9tjcwgeD"
      },
      "source": [
        "- To load custom config and weight, you can pass the path to the config file to `model` and the path to the weight to `weights`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eukDD4Rzwp9P",
        "outputId": "0a34392c-0544-4a90-c844-7628d184efc0"
      },
      "outputs": [],
      "source": [
        "# Choose to use a config\n",
        "config_path = './configs/rtmdet/rtmdet_tiny_8xb32-300e_coco.py'\n",
        "\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = './checkpoints/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n",
        "\n",
        "# Initialize the DetInferencer\n",
        "inferencer = DetInferencer(model=config_path, weights=checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC1je9iiTuMS"
      },
      "source": [
        "- By default, [MMEngine](https://github.com/open-mmlab/mmengine/) dumps config to the weight. If you have a weight trained on MMEngine, you can also pass the path to the weight file to `weights` without specifying `model`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kenyo80RTx63",
        "outputId": "46fe8219-d1a7-4e45-b5a1-b6d21c30be42"
      },
      "outputs": [],
      "source": [
        "# It will raise an error if the config file cannot be found in the weight. Currently, within the MMDetection model repository, only the weights of ddq-detr-4scale_r50 can be loaded in this manner.\n",
        "inferencer = DetInferencer(weights='https://download.openmmlab.com/mmdetection/v3.0/ddq/ddq-detr-4scale_r50_8xb2-12e_coco/ddq-detr-4scale_r50_8xb2-12e_coco_20230809_170711-42528127.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-AlYOw4T3AO"
      },
      "source": [
        "- Passing config file to `model` without specifying `weight` will result in a randomly initialized model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quFQ8abYT6As"
      },
      "source": [
        "### Device\n",
        "\n",
        "Each Inferencer instance is bound to a device.\n",
        "By default, the best device is automatically decided by [MMEngine](https://github.com/open-mmlab/mmengine/). You can also alter the device by specifying the `device` argument. For example, you can use the following code to create an Inferencer on GPU 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi6DRpsQPEmV",
        "outputId": "9eac2017-cce6-491a-ef51-3e7e2560f107"
      },
      "outputs": [],
      "source": [
        "inferencer = DetInferencer(model='rtmdet_tiny_8xb32-300e_coco', device='cuda:0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3pgIACHUXEv"
      },
      "source": [
        "To create an Inferencer on CPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsAotaiRUXWH",
        "outputId": "531b1cb0-e986-4e0a-91c9-6d3ad65544e7"
      },
      "outputs": [],
      "source": [
        "inferencer = DetInferencer(model='rtmdet_tiny_8xb32-300e_coco', device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a4Zw5plUisX"
      },
      "source": [
        "### Inference\n",
        "\n",
        "Once the Inferencer is initialized, you can directly pass in the raw data to be inferred and get the inference results from return values.\n",
        "\n",
        "#### Input\n",
        "\n",
        "Input can be either of these types:\n",
        "\n",
        "- str: Path/URL to the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2abd7eef6f1f4b9c865a466b3dd5ef24",
            "8951ec1ee7164f7ca7239a37e80e98ea"
          ]
        },
        "id": "C4McAmYdUnCL",
        "outputId": "50bea3e2-a912-497e-cee9-26109dccdc12"
      },
      "outputs": [],
      "source": [
        "inferencer = DetInferencer(model='rtmdet_tiny_8xb32-300e_coco', device='cuda:0')\n",
        "inferencer('demo/demo.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G_TPKrMUp2T"
      },
      "source": [
        "- array: Image in numpy array. It should be in BGR order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "59bfd22c751f4ed4baefa466e7653315",
            "0164804ae2f842fe8d2a4c5414c4a0c2"
          ]
        },
        "id": "-M1qGlfaUpha",
        "outputId": "5a06cfe8-e056-4d56-c8e9-489e8f6633a0"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "array = mmcv.imread('demo/demo.jpg')\n",
        "inferencer(array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I45B_CtzUuh2"
      },
      "source": [
        "- list: A list of basic types above. Each element in the list will be processed separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a64a6eb038c44236b80579b2bfc4b8e3",
            "eef25a0509854f98883395a2c0fc2134",
            "f87f0b153b0342ad99dcd320a1302c92",
            "f6634888109048069b6844e9f9b4ec13"
          ]
        },
        "id": "k1IXIWXHUwKP",
        "outputId": "0af73b0b-d703-4cbc-91ad-052f0b521d50"
      },
      "outputs": [],
      "source": [
        "inferencer(['tests/data/color.jpg', 'tests/data/gray.jpg'])\n",
        "# You can even mix the types\n",
        "inferencer(['tests/data/color.jpg', array])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUGrTtxrVBAS"
      },
      "source": [
        "- str: Path to the directory. All images in the directory will be processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "07ed8efcd87a40059af36f0c43ef5147",
            "69ce7e58e27f4e1186ab0afcb99d37c3"
          ]
        },
        "id": "JWK10ZD6VDDE",
        "outputId": "91418597-d9ea-4613-b141-16bc8bcc8caf"
      },
      "outputs": [],
      "source": [
        "inferencer('tests/data/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQxEVr2pVGen"
      },
      "source": [
        "### Output\n",
        "\n",
        "By default, each `Inferencer` returns the prediction results in a dictionary format.\n",
        "\n",
        "- `visualization` contains the visualized predictions.\n",
        "\n",
        "- `predictions` contains the predictions results in a json-serializable format. But it's an empty list by default unless `return_vis=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306,
          "referenced_widgets": [
            "95674a6baa1842d2981fe60b31ab6cad",
            "7e62816d1f6c441fb98c1f8e942fff1d"
          ]
        },
        "id": "m6a8T4goU8Sq",
        "outputId": "6f74098f-a3d3-4897-c58f-68fae88889af"
      },
      "outputs": [],
      "source": [
        "# Show the structure of result dict\n",
        "from rich.pretty import pprint\n",
        "\n",
        "result = inferencer('demo/demo.jpg')\n",
        "pprint(result, max_length=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a93hFT0jVkrR"
      },
      "source": [
        "If you wish to get the raw outputs from the model, you can set `return_datasamples` to `True` to get the original `DataSample`, which will be stored in `predictions`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "060f510b5bda498583d7212060bb528c",
            "1bb724cb12c240a18f651dd99842e5b0"
          ]
        },
        "id": "U5DFI7QAVbnP",
        "outputId": "effaf3ec-2476-4b64-dcbd-802a18a26479"
      },
      "outputs": [],
      "source": [
        "result = inferencer('demo/demo.jpg', return_datasamples=True)\n",
        "pprint(result, max_length=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHdcUnGzVsk1"
      },
      "source": [
        "#### Dumping Results\n",
        "\n",
        "Apart from obtaining predictions from the return value, you can also export the predictions/visualizations to files by setting `out_dir` and `no_save_pred`/`no_save_vis` arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "38083c2f29604d1d9a7dcf9845dfbf33",
            "54cdfe55e0f04df9ab844961a089fe2f"
          ]
        },
        "id": "0dr-ixmfVtng",
        "outputId": "af22d458-9aed-41e2-f675-e017a0cb588b"
      },
      "outputs": [],
      "source": [
        "inferencer('demo/demo.jpg', out_dir='outputs/', no_save_pred=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RTMDet Quick Start Guide\n",
        "\n",
        "RTMDet is a state-of-the-art real-time object detector that offers excellent speed-accuracy trade-offs. This section demonstrates how to use different RTMDet models for object detection.\n",
        "\n",
        "## Available RTMDet Models:\n",
        "- **RTMDet-tiny**: Fast and lightweight (41.1% AP, ~1ms)\n",
        "- **RTMDet-s**: Small model (44.6% AP, ~1.2ms) \n",
        "- **RTMDet-m**: Medium model (49.4% AP, ~1.6ms)\n",
        "- **RTMDet-l**: Large model (51.5% AP, ~2.4ms)\n",
        "- **RTMDet-x**: Extra large model (52.8% AP, ~3.1ms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from mmdet.apis import DetInferencer\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Initialize RTMDet model - starting with RTMDet-s (small) for good balance of speed and accuracy\n",
        "rtmdet_inferencer = DetInferencer(\n",
        "    model='configs/rtmdet/rtmdet_s_8xb32-300e_coco.py',\n",
        "    weights='https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_s_8xb32-300e_coco/rtmdet_s_8xb32-300e_coco_20220905_161602-387a891e.pth',\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")\n",
        "\n",
        "print(\"RTMDet-s model loaded successfully!\")\n",
        "print(f\"Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run inference on the demo image\n",
        "results = rtmdet_inferencer('demo/demo.jpg', show=True, out_dir='outputs/rtmdet/')\n",
        "\n",
        "# The results contain detection information\n",
        "print(\"Detection completed!\")\n",
        "print(f\"Number of predictions: {len(results['predictions'][0]['bboxes']) if results['predictions'] else 0}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing Different RTMDet Model Sizes\n",
        "\n",
        "Let's compare the performance of different RTMDet variants:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Define RTMDet model configurations\n",
        "rtmdet_models = {\n",
        "    'RTMDet-tiny': {\n",
        "        'config': 'configs/rtmdet/rtmdet_tiny_8xb32-300e_coco.py',\n",
        "        'checkpoint': 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_tiny_8xb32-300e_coco/rtmdet_tiny_8xb32-300e_coco_20220902_112414-78e30dcc.pth'\n",
        "    },\n",
        "    'RTMDet-s': {\n",
        "        'config': 'configs/rtmdet/rtmdet_s_8xb32-300e_coco.py', \n",
        "        'checkpoint': 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_s_8xb32-300e_coco/rtmdet_s_8xb32-300e_coco_20220905_161602-387a891e.pth'\n",
        "    },\n",
        "    'RTMDet-m': {\n",
        "        'config': 'configs/rtmdet/rtmdet_m_8xb32-300e_coco.py',\n",
        "        'checkpoint': 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_m_8xb32-300e_coco/rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Function to benchmark a model\n",
        "def benchmark_rtmdet(model_name, config, checkpoint, image_path='demo/demo.jpg', num_runs=5):\n",
        "    print(f\"\\n=== Benchmarking {model_name} ===\")\n",
        "    \n",
        "    # Initialize inferencer\n",
        "    inferencer = DetInferencer(\n",
        "        model=config,\n",
        "        weights=checkpoint,\n",
        "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    )\n",
        "    \n",
        "    # Warm up\n",
        "    inferencer(image_path, show=False)\n",
        "    \n",
        "    # Benchmark\n",
        "    times = []\n",
        "    for i in range(num_runs):\n",
        "        start_time = time.time()\n",
        "        results = inferencer(image_path, show=False)\n",
        "        end_time = time.time()\n",
        "        times.append(end_time - start_time)\n",
        "    \n",
        "    avg_time = np.mean(times)\n",
        "    fps = 1.0 / avg_time\n",
        "    \n",
        "    # Get number of detections\n",
        "    num_detections = len(results['predictions'][0]['bboxes']) if results['predictions'] else 0\n",
        "    \n",
        "    print(f\"Average inference time: {avg_time:.3f}s\")\n",
        "    print(f\"FPS: {fps:.1f}\")\n",
        "    print(f\"Number of detections: {num_detections}\")\n",
        "    \n",
        "    return avg_time, fps, num_detections\n",
        "\n",
        "# Note: Uncomment the lines below to run the benchmark\n",
        "# This might take a few minutes as it downloads and tests multiple models\n",
        "\n",
        "print(\"RTMDet model comparison setup complete!\")\n",
        "print(\"Uncomment the benchmark code below to compare model performance.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mmdet311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0164804ae2f842fe8d2a4c5414c4a0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0226fedc26044ab2abdccc4fcbe226f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "060f510b5bda498583d7212060bb528c": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_1bb724cb12c240a18f651dd99842e5b0",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span>  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m  \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "07ed8efcd87a40059af36f0c43ef5147": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_69ce7e58e27f4e1186ab0afcb99d37c3",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span> <span style=\"color: #800080; text-decoration-color: #800080\">13.5 it/s</span> <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m \u001b[35m13.5 it/s\u001b[0m \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "1bb724cb12c240a18f651dd99842e5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2abd7eef6f1f4b9c865a466b3dd5ef24": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8951ec1ee7164f7ca7239a37e80e98ea",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span>  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m  \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "38083c2f29604d1d9a7dcf9845dfbf33": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_54cdfe55e0f04df9ab844961a089fe2f",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span>  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m  \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "54cdfe55e0f04df9ab844961a089fe2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59bfd22c751f4ed4baefa466e7653315": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0164804ae2f842fe8d2a4c5414c4a0c2",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span>  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m  \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "69ce7e58e27f4e1186ab0afcb99d37c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa2cda48fda43f9bf53a0f533392eba": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0226fedc26044ab2abdccc4fcbe226f8",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span>  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m  \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "7e62816d1f6c441fb98c1f8e942fff1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8951ec1ee7164f7ca7239a37e80e98ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95674a6baa1842d2981fe60b31ab6cad": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7e62816d1f6c441fb98c1f8e942fff1d",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span>  <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m  \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "a64a6eb038c44236b80579b2bfc4b8e3": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_eef25a0509854f98883395a2c0fc2134",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span> <span style=\"color: #800080; text-decoration-color: #800080\">9.7 it/s</span> <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m \u001b[35m9.7 it/s\u001b[0m \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "eef25a0509854f98883395a2c0fc2134": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6634888109048069b6844e9f9b4ec13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87f0b153b0342ad99dcd320a1302c92": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f6634888109048069b6844e9f9b4ec13",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Inference <span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ</span><span style=\"color: #f42670; text-decoration-color: #f42670\">‚îÅ</span><span style=\"color: #e6276c; text-decoration-color: #e6276c\">‚îÅ</span><span style=\"color: #d12a66; text-decoration-color: #d12a66\">‚îÅ</span><span style=\"color: #b72c5e; text-decoration-color: #b72c5e\">‚îÅ</span><span style=\"color: #993056; text-decoration-color: #993056\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span><span style=\"color: #3e393b; text-decoration-color: #3e393b\">‚îÅ</span><span style=\"color: #4c383f; text-decoration-color: #4c383f\">‚îÅ</span><span style=\"color: #613545; text-decoration-color: #613545\">‚îÅ</span><span style=\"color: #7b334d; text-decoration-color: #7b334d\">‚îÅ</span> <span style=\"color: #800080; text-decoration-color: #800080\">9.0 it/s</span> <span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n</pre>\n",
                  "text/plain": "Inference \u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚îÅ\u001b[0m\u001b[38;2;244;38;112m‚îÅ\u001b[0m\u001b[38;2;230;39;108m‚îÅ\u001b[0m\u001b[38;2;209;42;102m‚îÅ\u001b[0m\u001b[38;2;183;44;94m‚îÅ\u001b[0m\u001b[38;2;153;48;86m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;58;58;58m‚îÅ\u001b[0m\u001b[38;2;62;57;59m‚îÅ\u001b[0m\u001b[38;2;76;56;63m‚îÅ\u001b[0m\u001b[38;2;97;53;69m‚îÅ\u001b[0m\u001b[38;2;123;51;77m‚îÅ\u001b[0m \u001b[35m9.0 it/s\u001b[0m \u001b[36m \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
